{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy \n",
    "import nltk\n",
    "import time\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#please change the file which will be used as the training set\n",
    "df = pd.read_csv('moviereviews/train.tsv', sep='\\t')\n",
    "#uncomment for the running time computation\n",
    "#start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing techniques \n",
    "#INSTRUCTIONS: if you want to use one of them, then please change the value from False to True\n",
    "#initialy it is set to obtain the highest accuracy\n",
    "capitalisation = True\n",
    "stop_words_function = False\n",
    "stemming = False\n",
    "pos_tag = False\n",
    "Lemmatisation = False\n",
    "punctuation_removal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer 5 value to 3 value\n",
    "def Transfer(input_path, output_path):\n",
    "    df = pd.read_csv(input_path, sep='\\t')\n",
    "\n",
    "    sentimentdict = {'sentimentId':[], 'sentimentText':[], 'sentimentValue':[]}\n",
    "\n",
    "    for i in range(len(df)): \n",
    "        sentimentdict['sentimentId'].append(df.loc[i][0]) \n",
    "        sentimentdict['sentimentText'].append(df.loc[i][1])\n",
    "        sentlen = len(nltk.word_tokenize(df.loc[i][1]))\n",
    "        if df.loc[i][2] == 0: \n",
    "            sentimentdict['sentimentValue'].append(0) \n",
    "\n",
    "        elif df.loc[i][2] == 1:\n",
    "            sentimentdict['sentimentValue'].append(0)\n",
    "\n",
    "        elif df.loc[i][2] == 2:\n",
    "            sentimentdict['sentimentValue'].append(1)\n",
    "\n",
    "        elif df.loc[i][2] == 3:\n",
    "            sentimentdict['sentimentValue'].append(2)\n",
    "\n",
    "        elif df.loc[i][2] == 4:\n",
    "            sentimentdict['sentimentValue'].append(2) \n",
    "\n",
    "    dataFrameDict = {'SentenceId': sentimentdict['sentimentId'], 'Phrase': sentimentdict['sentimentText'], \n",
    "            'Sentiment': sentimentdict['sentimentValue']}\n",
    "\n",
    "    dfdev = pd.DataFrame(dataFrameDict)\n",
    "\n",
    "    #saving the dataframe\n",
    "    dfdev.to_csv(output_path, sep='\\t', index=False)\n",
    "    \n",
    "#the file generated below will be used in the evaluation part\n",
    "#INSTRUCTIONS: first parameter used as the file from which the 3 sentiment output(2nd parameter) will be made\n",
    "Transfer('moviereviews/dev.tsv', 'dev3.tsv')\n",
    "#train set is not used in my training but the file was also generated \n",
    "#Transfer('moviereviews/train.tsv', 'train3sentiment.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding new words to the corpus\n",
    "def calcocu(opinion, dicto): \n",
    "    for i in opinion:\n",
    "        if i in dicto.keys():\n",
    "            dicto[i] = dicto[i] + 1\n",
    "        else:\n",
    "            dicto[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Processing techniques\n",
    "def Processing(opinion): \n",
    "    propinion = []\n",
    "    lemopinion = []\n",
    "    #capitalisation\n",
    "    if capitalisation == True:\n",
    "        for i in range(len(opinion)):\n",
    "            opinion[i] = opinion[i].lower()\n",
    "    #punctuation removal\n",
    "    if punctuation_removal == True:\n",
    "        opinion = [word for word in opinion if word.isalpha()]\n",
    "    #stop words removal\n",
    "    if stop_words_function == True:\n",
    "        stop_words = nltk.corpus.stopwords.words('english')\n",
    "        opinion = [word for word in opinion if word not in stop_words]\n",
    "    #pos tag\n",
    "    if pos_tag == True:\n",
    "        opinion = nltk.pos_tag(opinion)\n",
    "        for i in range(len(opinion)):\n",
    "            if opinion[i][1] == 'JJ' or opinion[i][1] == 'RB' or opinion[i][1] == 'JJR' or opinion[i][1] == 'RBR' or opinion[i][1] == 'JJS' or opinion[i][1] == 'RBS':\n",
    "                propinion.append(opinion[i][0])\n",
    "        opinion = propinion\n",
    "    #lemmatisation\n",
    "    if Lemmatisation == True:\n",
    "        lemmatizer = nltk.WordNetLemmatizer()\n",
    "        for i in opinion:\n",
    "            lemopinion.append(lemmatizer.lemmatize(i))\n",
    "        opinion = lemopinion\n",
    "    #stemming\n",
    "    if stemming == True:\n",
    "        #INSTRUCTIONS: to implement one of the Stemmers tested in the report \n",
    "        #please replace the '' to either:\n",
    "        #nltk.stem.RSLPStemmer()\n",
    "        #nltk.stem.SnowballStemmer(\"english\")\n",
    "        #nltk.stem.lancaster.LancasterStemmer()\n",
    "        #depending on the Stemmer you want to use\n",
    "        #porter =  nltk.stem.porter.PorterStemmer()\n",
    "        porter =  nltk.stem.porter.PorterStemmer()\n",
    "        opinion = [porter.stem(word) for word in opinion]\n",
    "    return opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus computation and extension with selected words\n",
    "def corpusBuilder(text5dict, text3dict, word5dict, word3dict, opinion, dict5calc, dict3calc):\n",
    "        text5valuedict[text5dict] = text5valuedict[text5dict] + 1 \n",
    "        text3valuedict[text3dict] = text3valuedict[text3dict] + 1\n",
    "        text5valuedict[word5dict] = text5valuedict[word5dict] + sentlen\n",
    "        text3valuedict[word3dict] = text3valuedict[word3dict] + sentlen\n",
    "        calcocu(opinion, dict5calc)\n",
    "        calcocu(opinion, dict3calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall precision calculator for 5 sentiment\n",
    "def RecPrec5(value1, value2, value3, value4, value5, resu5v):\n",
    "    return resu5v[value1]/(resu5v[value1] + resu5v[value2] + resu5v[value3] + resu5v[value4] + resu5v[value5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall precision calculator for 3 sentiment\n",
    "def RecPrec3(value1, value2, value3, resu3v):\n",
    "    return resu3v[value1]/(resu3v[value1] + resu3v[value2] + resu3v[value3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TSV Files generation\n",
    "def tsvgen(sentimentdict, file1, file2):\n",
    "    dataFrameDict3v = {'SentenceId': sentimentdict['sentimentId'], 'Sentiment': sentimentdict['sentimentValue3v']}\n",
    "\n",
    "    dataFrameDict5v = {'SentenceId': sentimentdict['sentimentId'], 'Sentiment': sentimentdict['sentimentValue5v']}\n",
    "    dfdev3v = pd.DataFrame(dataFrameDict3v)\n",
    "    dfdev5v = pd.DataFrame(dataFrameDict5v)\n",
    "\n",
    "    #saving the dataframe\n",
    "    dfdev3v.to_csv(file1, sep='\\t', index=False)\n",
    "    dfdev5v.to_csv(file2, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1 score calculation\n",
    "def f1calc(precision, recall):\n",
    "    return (2*precision*recall)/(precision + recall)\n",
    "#general average calculator\n",
    "def average(precreclist):\n",
    "    return sum(precreclist)/len(precreclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the function which computes and displayes the final values of f1 score, precision, accuracy and recall\n",
    "def resultpresent(resu5v, resu3v, acc5v, acc3v, labelled, devf):\n",
    "    if labelled==False:\n",
    "        precision3v = {'0':RecPrec3('00','01','02', resu3v), '1':RecPrec3('10','11','12', resu3v), \n",
    "                       '2':RecPrec3('20','21','22', resu3v)}\n",
    "\n",
    "        precision5v = {'0':RecPrec5('00','01','02','03','04', resu5v), '1':RecPrec5('10','11','12','13','14', resu5v),\n",
    "                      '2':RecPrec5('20','21','22','23','24', resu5v), '3':RecPrec5('30','31','32','33','34', resu5v),\n",
    "                       '4':RecPrec5('40','41','42','43','44', resu5v)}\n",
    "\n",
    "        recall5v = {'0':RecPrec5('00','10','20','30','40', resu5v), '1':RecPrec5('11','01','21','31','41', resu5v),\n",
    "                    '2':RecPrec5('22','02','12','32','42', resu5v), '3':RecPrec5('33','13','23','03','43', resu5v),\n",
    "                    '4':RecPrec5('44','04','14','24','34', resu5v)}\n",
    "\n",
    "        recall3v = {'0':RecPrec3('00','10','20', resu3v),\n",
    "                    '1':RecPrec3('11','01','21', resu3v),\n",
    "                    '2':RecPrec3('22','02','12', resu3v)}\n",
    "\n",
    "        print(\"========ACCURACY========\")\n",
    "        print(\"5 sentiment: \", acc5v/len(devf))\n",
    "        print(\"3 sentiment: \", acc3v/len(devf))\n",
    "        print(\"========RECALL========\")\n",
    "        print(\"5 recall: \", average([recall5v['0'], recall5v['1'], recall5v['2'], recall5v['3'], recall5v['4']]))\n",
    "        print(\"3 recall: \", average([recall3v['0'], recall3v['1'], recall3v['2']]))\n",
    "        print(\"======PRECISION======\")\n",
    "        print(\"5 precision: \", average([precision5v['0'], precision5v['1'], precision5v['2'], precision5v['3'], precision5v['4']]))\n",
    "        print(\"3 precision: \", average([precision3v['0'], precision3v['1'], precision3v['2']]))\n",
    "        print(\"========F1SCORE========\")\n",
    "        print(\"5 F1 Score: \", f1calc(average([precision5v['0'], precision5v['1'], precision5v['2'], precision5v['3'], precision5v['4']]), average([recall5v['0'], recall5v['1'], recall5v['2'], recall5v['3'], recall5v['4']])))\n",
    "        print(\"3 F1 Score: \", f1calc(average([precision3v['0'], precision3v['1'], precision3v['2']]), average([recall3v['0'], recall3v['1'], recall3v['2']])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HEATMAP Generator\n",
    "#two seperate generators for 3 and 5 sentiment results\n",
    "def heatmap3(resu3v, filename):\n",
    "    heatmap3v = numpy.array([[resu3v['00'],resu3v['01'],resu3v['02']],\n",
    "                             [resu3v['10'],resu3v['11'],resu3v['12']],\n",
    "                             [resu3v['20'],resu3v['21'],resu3v['22']]])\n",
    "    hm3=seaborn.heatmap(heatmap3v, annot=True, cmap = 'coolwarm', fmt='d')\n",
    "    #labelling the heatmap axis\n",
    "    plt.title(\"3 sentiment value map\")\n",
    "    plt.ylabel('predicted values')\n",
    "    plt.xlabel('actual values')\n",
    "    hm3.figure.savefig(filename)\n",
    "    hm3.figure.clf()\n",
    "\n",
    "def heatmap5(resu5v, filename):    \n",
    "    heatmap5v = numpy.array([[resu5v['00'],resu5v['01'],resu5v['02'],resu5v['03'],resu5v['04']],\n",
    "                             [resu5v['10'],resu5v['11'],resu5v['12'],resu5v['13'],resu5v['14']],\n",
    "                             [resu5v['20'],resu5v['21'],resu5v['22'],resu5v['23'],resu5v['24']],\n",
    "                             [resu5v['30'],resu5v['31'],resu5v['32'],resu5v['33'],resu5v['34']],\n",
    "                             [resu5v['40'],resu5v['41'],resu5v['42'],resu5v['43'],resu5v['44']]])\n",
    "    hm5=seaborn.heatmap(heatmap5v, annot=True, cmap = 'coolwarm', fmt='d')\n",
    "    #labelling the heatmap axis\n",
    "    plt.title(\"5 sentiment value map\")\n",
    "    plt.ylabel('predicted values')\n",
    "    plt.xlabel('actual values')\n",
    "    hm5.figure.savefig(filename)\n",
    "    hm5.figure.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main corpus builder\n",
    "#if you want to see how long it takes to run the cell please uncomment end and start\n",
    "#start = time.time() \n",
    "\n",
    "#change this variables to the dictionary later \n",
    "text5valuedict = {'neg0':0, 'neg1':0, 'neu':0, 'pos3':0, 'pos4':0, \n",
    "                  'wordneg0':0, 'wordneg1':0, 'wordneu':0, 'wordpos3':0, 'wordpos4':0}\n",
    "\n",
    "text3valuedict = {'neg3v':0, 'neu3v':0, 'pos3v':0, 'wordneg3v':0, 'wordneu3v':0, 'wordpos3v':0}\n",
    "\n",
    "negd0 = {}\n",
    "negd1 = {}\n",
    "neud = {}\n",
    "posd3 = {}\n",
    "posd4 = {}\n",
    "negd3v = {}\n",
    "neud3v = {}\n",
    "posd3v = {}\n",
    "   \n",
    "for i in range(len(df)): \n",
    "    opinion_raw = nltk.word_tokenize(df.loc[i][1])\n",
    "    opinion = Processing(opinion_raw)\n",
    "    sentlen = len(opinion)\n",
    "    if df.loc[i][2] == 0: \n",
    "        corpusBuilder('neg0', 'neg3v', 'wordneg0', 'wordneg3v', opinion, negd0, negd3v)\n",
    "     \n",
    "    elif df.loc[i][2] == 1:\n",
    "        corpusBuilder('neg1', 'neg3v', 'wordneg1', 'wordneg3v', opinion, negd1, negd3v)\n",
    "       \n",
    "    elif df.loc[i][2] == 2:\n",
    "        corpusBuilder('neu', 'neu3v', 'wordneu', 'wordneu3v', opinion, neud, neud3v)\n",
    "       \n",
    "    elif df.loc[i][2] == 3:\n",
    "        corpusBuilder('pos3', 'pos3v', 'wordpos3', 'wordpos3v', opinion, posd3, posd3v)\n",
    "        \n",
    "    elif df.loc[i][2] == 4:\n",
    "        corpusBuilder('pos4', 'pos3v', 'wordpos4', 'wordpos3v', opinion, posd4, posd3v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior values and total number of 3 and 5 sentiment numbers\n",
    "total5 = text5valuedict['neg0']+text5valuedict['neg1']+text5valuedict['neu']+text5valuedict['pos3']+text5valuedict['pos4']\n",
    "total3 = text3valuedict['neg3v']+text3valuedict['neu3v']+text3valuedict['pos3v']\n",
    "\n",
    "#totalwords represents the total number of the unique words in the whole training set\n",
    "totalwords = {}\n",
    "\n",
    "totalwords = ((set(negd3v.keys())).union(set(neud3v.keys()))).union(set(posd3v.keys()))\n",
    "\n",
    "#prior values calculation\n",
    "priorneg0 = text5valuedict['neg0']/total5\n",
    "priorneg1 = text5valuedict['neg1']/total5\n",
    "priorneu = text5valuedict['neu']/total5\n",
    "priorpos3 = text5valuedict['pos3']/total5\n",
    "priorpos4 = text5valuedict['pos4']/total5\n",
    "\n",
    "priorpos3v = text3valuedict['pos3v']/total3\n",
    "priorneu3v = text3valuedict['neu3v']/total3\n",
    "priorneg3v = text3valuedict['neg3v']/total3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main evaluation function\n",
    "def Evaluation(file5sentiment, file_output1, file_output2, image3name, image5name, file3sentiment=None):\n",
    "    if file3sentiment != None:\n",
    "        devf2 = pd.read_csv(file3sentiment, sep='\\t')\n",
    "    devf = pd.read_csv(file5sentiment, sep='\\t')\n",
    "    acc5v = 0\n",
    "    acc3v = 0\n",
    "    #this is the grid for the matrix to compute and display results\n",
    "    resu5v = {'00':0,'01':0,'02':0,'03':0,'04':0,\n",
    "              '10':0,'11':0,'12':0,'13':0,'14':0,\n",
    "              '20':0,'21':0,'22':0,'23':0,'24':0,\n",
    "              '30':0,'31':0,'32':0,'33':0,'34':0,\n",
    "              '40':0,'41':0,'42':0,'43':0,'44':0}\n",
    "    \n",
    "    #this is the grid for the matrix to compute and display results\n",
    "    resu3v = {'00':0,'01':0,'02':0,\n",
    "              '10':0,'11':0,'12':0,\n",
    "              '20':0,'21':0,'22':0}\n",
    "    labelled = False\n",
    "\n",
    "    sentimentdict = {'sentimentId':[], 'sentimentText':[], 'sentimentValue3v':[], 'sentimentValue5v':[]}\n",
    "\n",
    "    for row in range(len(devf)):\n",
    "        senpos3 = priorpos3 \n",
    "        senpos4 = priorpos4 \n",
    "        senneu = priorneu\n",
    "        senneg0 = priorneg0\n",
    "        senneg1 = priorneg1\n",
    "\n",
    "        senneg3v = priorneg3v\n",
    "        senneu3v = priorneu3v\n",
    "        senpos3v = priorpos3v \n",
    "\n",
    "        sentimentdict['sentimentId'].append(devf.loc[row][0]) \n",
    "\n",
    "        opinion_raw = nltk.word_tokenize(devf.loc[row][1])\n",
    "        opinion = Processing(opinion_raw)\n",
    "\n",
    "        for i in opinion:\n",
    "            if i not in posd3:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senpos3 = senpos3*(1/(text5valuedict['wordpos3']+len(totalwords)))\n",
    "            else:\n",
    "                senpos3 = senpos3*((posd3[i] + 1)/(text5valuedict['wordpos3']+len(totalwords)))\n",
    "            if i not in posd4:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senpos4 = senpos4*(1/(text5valuedict['wordpos4']+len(totalwords)))\n",
    "            else:    \n",
    "                senpos4 = senpos4*((posd4[i]+1)/(text5valuedict['wordpos4']+len(totalwords)))\n",
    "            if i not in neud:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senneu = senneu*(1/(text5valuedict['wordneu']+len(totalwords)))\n",
    "            else:    \n",
    "                senneu = senneu*((neud[i]+1)/(text5valuedict['wordneu']+len(totalwords)))\n",
    "            if i not in negd0:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senneg0 = senneg0*(1/(text5valuedict['wordneg0']+len(totalwords)))\n",
    "            else:    \n",
    "                senneg0 = senneg0*((negd0[i]+1)/(text5valuedict['wordneg0']+len(totalwords)))\n",
    "            if i not in negd1:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senneg1 = senneg1*(1/(text5valuedict['wordneg1']+len(totalwords)))\n",
    "            else:    \n",
    "                senneg1 = senneg1*((negd1[i]+1)/(text5valuedict['wordneg1']+len(totalwords)))\n",
    "\n",
    "            #3 values evaluation\n",
    "            if i not in negd3v:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senneg3v = senneg3v*(1/(text3valuedict['wordneg3v']+len(totalwords)))\n",
    "            else:    \n",
    "                senneg3v = senneg3v*((negd3v[i]+1)/(text3valuedict['wordneg3v']+len(totalwords)))\n",
    "            if i not in neud3v:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senneu3v = senneu3v*(1/(text3valuedict['wordneu3v']+len(totalwords)))\n",
    "            else:    \n",
    "                senneu3v = senneu3v*((neud3v[i]+1)/(text3valuedict['wordneu3v']+len(totalwords)))\n",
    "            if i not in posd3v:\n",
    "                #change the value below to 0 for the no-smoothing results\n",
    "                senpos3v = senpos3v*(1/(text3valuedict['wordpos3v']+len(totalwords)))\n",
    "            else:    \n",
    "                senpos3v = senpos3v*((posd3v[i]+1)/(text3valuedict['wordpos3v']+len(totalwords)))\n",
    "\n",
    "        s5 = numpy.array([senneg0, senneg1, senneu, senpos3, senpos4])\n",
    "        s3 = numpy.array([senneg3v, senneu3v, senpos3v])\n",
    "        sen5v = numpy.argmax(s5)\n",
    "        sen3v = numpy.argmax(s3)\n",
    "        sentimentdict['sentimentValue5v'].append(sen5v)\n",
    "        sentimentdict['sentimentValue3v'].append(sen3v)\n",
    "        #checks whether the data is labelled(dev) or blank(test)\n",
    "        try:\n",
    "            if sen5v == devf.loc[row][2]:\n",
    "                acc5v = acc5v + 1\n",
    "            keyresu5v = str(sen5v)+str(devf.loc[row][2])\n",
    "            resu5v[keyresu5v] = resu5v[keyresu5v] + 1\n",
    "\n",
    "            if sen3v == devf2.loc[row][2]:\n",
    "                acc3v = acc3v + 1\n",
    "            keyresu3v = str(sen3v)+str(devf2.loc[row][2])\n",
    "            resu3v[keyresu3v] = resu3v[keyresu3v] + 1  \n",
    "        except IndexError:\n",
    "        #if file is blank then do not calculate accuracy\n",
    "            acc5v = 0\n",
    "            acc3v = 0\n",
    "            labelled = True\n",
    "    #if file is blank then it does not calculate values below        \n",
    "    if labelled == False:\n",
    "        resultpresent(resu5v, resu3v, acc5v, acc3v, labelled, devf)\n",
    "        heatmap3(resu3v, image3name)\n",
    "        heatmap5(resu5v, image5name)\n",
    "    tsvgen(sentimentdict, file_output1, file_output2)\n",
    "#evaluation function runs\n",
    "Evaluation('moviereviews/dev.tsv', 'dev_predictions_3classes_KACPER_LODZINSKI.tsv', 'dev_predictions_5classes_KACPER_LODZINSKI.tsv', 'dev3.png', 'dev5.png', 'dev3.tsv')\n",
    "Evaluation('moviereviews/test.tsv', 'test_predictions_3classes_KACPER_LODZINSKI.tsv', 'test_predictions_5classes_KACPER_LODZINSKI.tsv', 'test3.png', 'test5.png')\n",
    "#INSTRUCTIONS: to evaluate the model on the different files please change the evaluation() method\n",
    "#Evaluation(nameofthefiletoteston5sentiment, generatedfileresults5sentiment, \n",
    "#generatedfileresults3sentiment, heatmap3sentimentfile, heatmap5sentimentfile, nameofthefiletoteston3sentiment(not required))\n",
    "\n",
    "#uncomment to check the total running time\n",
    "#end = time.time()\n",
    "#print(end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
